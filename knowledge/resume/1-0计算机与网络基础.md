## 计算机基础

### 操作系统

#### SSD能当内存用吗？

#### 什么是虚拟内存？

### 加密技术

#### RSA非对称加密

#### MD5介绍一下

128位；MD5即Message-Digest Algorithm 5（信息-摘要算法5），用于确保信息传输完整一致。是计算机广泛使用的杂凑算法之一（又译[摘要算法](https://baike.baidu.com/item/摘要算法)、[哈希算法](https://baike.baidu.com/item/哈希算法)），主流编程语言普遍已有MD5实现。

用途：

- 消息防篡改验证
- 文件分发篡改验证

### 编译原理

#### JavaCC的工作原理

![在这里插入图片描述](images/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1FYQzEyODE=,size_16,color_FFFFFF,t_70.jpg)



## 算法与数据结构

### 做题思路

1. 先画图分析
2. 写算法（递归？）
3. 对数器验算（使用系统提供的算法，或实现一个简单的算法）

### 数据结构

#### 单向链表

#### 双向链表

#### 栈

- 如何用两个栈实现队列？

#### 队列

- 数组实现（RingBuffer）：记住数组limit和size，putindex/pollindex

- 链表实现：
- 两个队列实现栈？

#### 双端队列

#### 单调栈

#### 线性表

线性表，全名为线性存储结构。使用线性表存储数据的方式可以这样理解，即“把所有数据用一根线儿[串](http://data.biancheng.net/view/175.html)起来，再存储到物理空间中”。

#### 最大堆最小堆

#### 哈希表

所有操作的时间复杂度都是O(1)

TreeMap所有的操作时间复杂度为O(logN)

基础类型按值传递（拷贝一份数据），非基础类型按引用传递

#### 跳表

### 算法思想

#### 分治思想

分治算法的基本思想是将一个规模为N的问题分解为K个规模较小的子问题，这些子问题相互独立且与原问题性质相同。 求出子问题的解，就可得到原问题的解。 即一种分目标完成程序算法，简单问题可用二分法完成。

1. 二分法

   > - 二分搜索
   > - 快速排序
   > - 线性时间选择
   > - 汉诺塔
   > - 棋盘覆盖
   > - 循环赛日程表

2. N分法

3. 哈希分治

> - 两个记录着url的16g文件，如何找到在两个文件中都有的URL

3. 递归

   > 

#### 贪心算法

#### 动态规划

> 动态规划也是一种分治思想（比如其状态转移方程就是一种分治），但与分治算法不同的是，分治算法是把原问题分解为若干个子问题，自顶向下求解子问题，合并子问题的解，从而得到原问题的解。动态规划也是把原始问题分解为若干个子问题，然后自底向上，**先求解最小的子问题，把结果存在表格中**，在求解大的子问题时，直接从表格中查询小的子问题的解，避免重复计算，从而提高算法效率。
>
> 所有的暴力递归，都可以改写为动态规划
>
> 先写dp数组，基于递归算法改写（所以要先），从小问题

#### 递归

BaseCase

如果是严格的非条件状态转移，可以使用斐波那契数列

如果每次计算是有条件的，使用动态规划

所有的递归都可以改写为迭代

#### 回溯

#### 分枝界定（Branch and Bound）

分支定界法（branch and bound）是一种求解整数规划问题的最常用算法。 这种方法不但可以求解纯整数规划，还可以求解混合整数规划问题。 分支定界法是一种搜索与迭代的方法，选择不同的分支变量和子问题进行分支。 对于两个变量的整数规划问题，使用网格的方法有时更为简单。

- 基本思想

  > **求解目标**：分支限界法的求解目标则是找出满足约束条件的一个解，或是在满足约束条件的解中找出在某种意义下的最优解。
  >
  > **搜索方式**：以广度优先或以最小耗费优先的方式搜索解空间树。分支限界法常以广度优先或以最小耗费（最大效益）优先的方式搜索问题的解空间树。
  >
  > 在分支限界法中，每一个活结点只有一次机会成为扩展结点。活结点一旦成为扩展结点，就一次性产生其所有儿子结点。在这些儿子结点中，导致不可行解或导致非最优解的儿子结点被舍弃，其余儿子结点被加入活结点表中。
  >
  > 此后，从活结点表中取下一结点成为当前扩展结点，并重复上述结点扩展过程。这个过程一直持续到找到所需的解或活结点表为空时为止。

### 排序算法

#### 特点比较

![img](images/sort.jpg)

#### 桶排序

#### 堆排序√

堆排序（Heapsort）是指利用堆这种数据结构所设计的一种排序算法。堆积是一个近似完全二叉树的结构，并同时满足堆积的性质：即子结点的键值或索引总是小于（或者大于）它的父节点。堆排序可以说是一种利用堆的概念来排序的选择排序。分为两种方法：

1. 大顶堆：每个节点的值都大于或等于其子节点的值，在堆排序算法中用于升序排列；
2. 小顶堆：每个节点的值都小于或等于其子节点的值，在堆排序算法中用于降序排列；

排序步骤：

1. 创建一个堆 H[0……n-1]；
2. 把堆首（最大值）和堆尾互换；
3. 把堆的尺寸缩小 1，并调用 shift_down(0)，目的是把新的数组顶端数据调整到相应位置；
4. 重复步骤 2，直到堆的尺寸为 1。

```java
public class HeapSort implements IArraySort {
    @Override
    public int[] sort(int[] sourceArray) throws Exception {
        // 对 arr 进行拷贝，不改变参数内容
        int[] arr = Arrays.copyOf(sourceArray, sourceArray.length);
        int len = arr.length;
        buildMaxHeap(arr, len);
        for (int i = len - 1; i > 0; i--) {
            swap(arr, 0, i);
            len--;
            heapify(arr, 0, len);
        }
        return arr;
    }
    private void buildMaxHeap(int[] arr, int len) {
        for (int i = (int) Math.floor(len / 2); i >= 0; i--) {
            heapify(arr, i, len);
        }
    }
    private void heapify(int[] arr, int i, int len) {
        int left = 2 * i + 1;
        int right = 2 * i + 2;
        int largest = i;
        if (left < len && arr[left] > arr[largest]) {
            largest = left;
        }
        if (right < len && arr[right] > arr[largest]) {
            largest = right;
        }
        if (largest != i) {
            swap(arr, i, largest);
            heapify(arr, largest, len);
        }
    }
    private void swap(int[] arr, int i, int j) {
        int temp = arr[i];
        arr[i] = arr[j];
        arr[j] = temp;
    }
}
```

#### 快速排序√

在平均状况下，排序 n 个项目要 Ο(nlogn) 次比较。在最坏状况下则需要 Ο(n2) 次比较，但这种状况并不常见。事实上，快速排序通常明显比其他 Ο(nlogn) 算法更快，因为它的内部循环（inner loop）可以在大部分的架构上很有效率地被实现出来。

> **快排与归并**：快速排序的最坏运行情况是 O(n²)，比如说顺序数列的快排。但它的平摊期望时间是 O(nlogn)，且 O(nlogn) 记号中隐含的常数因子很小，比复杂度稳定等于 O(nlogn) 的归并排序要小很多。所以，对绝大多数顺序性较弱的随机数列而言，快速排序总是优于归并排序。

```java
public class QuickSort implements IArraySort {
    @Override
    public int[] sort(int[] sourceArray) throws Exception {
        // 对 arr 进行拷贝，不改变参数内容
        int[] arr = Arrays.copyOf(sourceArray, sourceArray.length);
        return quickSort(arr, 0, arr.length - 1);
    }
    private int[] quickSort(int[] arr, int left, int right) {
        if (left < right) {
            int partitionIndex = partition(arr, left, right);
            quickSort(arr, left, partitionIndex - 1);
            quickSort(arr, partitionIndex + 1, right);
        }
        return arr;
    }
    private int partition(int[] arr, int left, int right) {
        // 设定基准值（pivot）
        int pivot = left;
        int index = pivot + 1;
        for (int i = index; i <= right; i++) {
            if (arr[i] < arr[pivot]) {
                swap(arr, i, index);
                index++;
            }
        }
        swap(arr, pivot, index - 1);
        return index - 1;
    }
    private void swap(int[] arr, int i, int j) {
        int temp = arr[i];
        arr[i] = arr[j];
        arr[j] = temp;
    }
}
```

#### 希尔排序√

希尔排序，也称递减增量排序算法，是插入排序的一种更高效的改进版本。但希尔排序是非稳定排序算法。

希尔排序是基于插入排序的以下两点性质而提出改进方法的：

- 插入排序在对几乎已经排好序的数据操作时，效率高，即可以达到线性排序的效率；
- 但插入排序一般来说是低效的，因为插入排序每次只能将数据移动一位；

希尔排序的基本思想是：先将整个待排序的记录序列分割成为若干子序列分别进行直接插入排序，待整个序列中的记录"基本有序"时，再对全体记录进行依次直接插入排序。

算法步骤

> - 选择一个增量序列 t1，t2，……，tk，其中 ti > tj, tk = 1；
>
> - 按增量序列个数 k，对序列进行 k 趟排序；
>
> 每趟排序，根据对应的增量 ti，将待排序列分割成若干长度为 m 的子序列，分别对各子表进行直接插入排序。仅增量因子为 1 时，整个序列作为一个表来处理，表长度即为整个序列的长度。

```java
public static void shellSort(int[] arr) {
    int length = arr.length;
    int temp;
    for (int step = length / 2; step >= 1; step /= 2) {
        for (int i = step; i < length; i++) {
            temp = arr[i];
            int j = i - step;
            while (j >= 0 && arr[j] > temp) {
                arr[j + step] = arr[j];
                j -= step;
            }
            arr[j + step] = temp;
        }
    }
}
```

#### 插入排序

将第一待排序序列第一个元素看做一个有序序列，把第二个元素到最后一个元素当成是未排序序列。

从头到尾依次扫描未排序序列，将扫描到的每个元素插入有序序列的适当位置。（如果待插入的元素与有序序列中的某个元素相等，则将待插入元素插入到相等元素的后面。）

```java
public class InsertSort implements IArraySort {
    @Override
    public int[] sort(int[] sourceArray) throws Exception {
        // 对 arr 进行拷贝，不改变参数内容
        int[] arr = Arrays.copyOf(sourceArray, sourceArray.length);
        // 从下标为1的元素开始选择合适的位置插入，因为下标为0的只有一个元素，默认是有序的
        for (int i = 1; i < arr.length; i++) {
            // 记录要插入的数据
            int tmp = arr[i];
            // 从已经排序的序列最右边的开始比较，找到比其小的数
            int j = i;
            while (j > 0 && tmp < arr[j - 1]) {
                arr[j] = arr[j - 1];
                j--;
            }
            // 存在比其小的数，插入
            if (j != i) {
                arr[j] = tmp;
            }
        }
        return arr;
    }
}
```



#### 归并排序√

归并排序（Merge Sort）是建立在归并操作上的一种有效，稳定的排序算法，该算法是采用分治法（Divide and Conquer）的一个非常典型的应用。 将已有序的子序列合并，得到完全有序的序列；即先使每个子序列有序，再使子序列段间有序。 若将两个有序表合并成一个有序表，称为二路归并。

![img](images/1557906108-5066-20161218163120151-452283750.jpg)

![img](images/1557906108-2034-20161218194508761-468169540.png)

![img](https://www.runoob.com/wp-content/uploads/2019/05/1557906108-7614-20161218194621308-588010220.png)

```java
public class MergeSort implements IArraySort {
    @Override
    public int[] sort(int[] sourceArray) throws Exception {
        // 对 arr 进行拷贝，不改变参数内容
        int[] arr = Arrays.copyOf(sourceArray, sourceArray.length);
        if (arr.length < 2) {
            return arr;
        }
        int middle = (int) Math.floor(arr.length / 2);
        int[] left = Arrays.copyOfRange(arr, 0, middle);
        int[] right = Arrays.copyOfRange(arr, middle, arr.length);
        return merge(sort(left), sort(right));
    }
    protected int[] merge(int[] left, int[] right) {
        int[] result = new int[left.length + right.length];
        int i = 0;
        while (left.length > 0 && right.length > 0) {
            if (left[0] <= right[0]) {
                result[i++] = left[0];
                left = Arrays.copyOfRange(left, 1, left.length);
            } else {
                result[i++] = right[0];
                right = Arrays.copyOfRange(right, 1, right.length);
            }
        }
        while (left.length > 0) {
            result[i++] = left[0];
            left = Arrays.copyOfRange(left, 1, left.length);
        }
        while (right.length > 0) {
            result[i++] = right[0];
            right = Arrays.copyOfRange(right, 1, right.length);
        }
        return result;
    }
}
```

#### 选择排序

首先在未排序序列中找到最小（大）元素，存放到排序序列的起始位置。

再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。

重复第二步，直到所有元素均排序完毕。

```java
public class SelectionSort implements IArraySort {
    @Override
    public int[] sort(int[] sourceArray) throws Exception {
        int[] arr = Arrays.copyOf(sourceArray, sourceArray.length);
        // 总共要经过 N-1 轮比较
        for (int i = 0; i < arr.length - 1; i++) {
            int min = i;
            // 每轮需要比较的次数 N-i
            for (int j = i + 1; j < arr.length; j++) {
                if (arr[j] < arr[min]) {
                    // 记录目前能找到的最小值元素的下标
                    min = j;
                }
            }
            // 将找到的最小值和i位置所在的值进行交换
            if (i != min) {
                int tmp = arr[i];
                arr[i] = arr[min];
                arr[min] = tmp;
            }
        }
        return arr;
    }
```

https://www.runoob.com/w3cnote/selection-sort.html

### 查找算法

#### 二分法查找

### 数学思想

#### 斐波那契数列

适用条件：**严格的、没有条件转移的表达式。**

### 状态机

#### AC自动机

#### 有限状态机

### 其它技巧

#### 位运算

- 不引入新的变量交换A，B两个变量的值；A=A\^B，B=A\^B，A=A\^B（条件：A/B不能指向同一个内存）

- 一个数组中，只有一种数出现了奇数词；所有的数异或，最终的结果就是出现奇数次的数。（偶数个相等的数异或结果为0）

- 提取最后一个二进制的1；N & ( ( ~N ) + 1 )

- 乘2：5<<1；乘4：5<<2；除16：80>>4

#### 二进制技巧

- 使用二进制随机数，可以生成任意范围的随机数

#### 双指针

双指针技巧还可以分为两类，一类是「快慢指针」，一类是「左右指针」。前者解决主要解决链表中的问题，比如典型的判定链表中是否包含环；后者主要解决数组（或者字符串）中的问题，比如二分查找。

#### 滑动窗口

### 经典算法题

#### 买卖股票的最佳时机

#### Z字打印二叉树

#### 二叉树镜像（递归）

```java
class Solution {
    public TreeNode mirrorTree(TreeNode root) {
        // 当节点为空时，直接返回
        if(root == null) return null;
        // 设置一个临时的节点 tmp 用来存储当前节点的左子树
        TreeNode tmp = root.left;
        // 以下两个操作是在交换当前节点的左右子树
        // 当前节点的左子树为节点的右子树
        // 同时递归下去，不停的交互子树中的节点
        root.left = mirrorTree(root.right);
        // 当前节点的右子树为节点的左子树
        // 同时递归下去，不停的交互子树中的节点
        root.right = mirrorTree(tmp);
        // 最后返回根节点
        return root;
    }
}
```

## 计算机网络

### 高可用，容灾和异地多活

#### 常见的负载均衡器

根据工作在的协议层划分可划分为：

- 四层负载均衡：根据请求报文中的目标地址和端口进行调度
- 七层负载均衡：根据请求报文的内容进行调度，这种调度属于「代理」的方式

根据软硬件划分：

- 硬件负载均衡：
  - F5 的 BIG-IP
  - Citrix 的 NetScaler
  - 这类硬件负载均衡器通常能同时提供四层和七层负载均衡，但同时也价格不菲
- 软件负载均衡：
  - TCP 层：LVS，HaProxy，Nginx
  - 基于 HTTP 协议：Haproxy，Nginx，ATS（Apache Traffic Server），squid，varnish
  - 基于 MySQL 协议：mysql-proxy

#### Linux高可用之Keepalived

Keepalived是用C语言编写的路由软件。该项目的主要目标是为Linux系统和基于Linux的基础结构提供负载均衡和高可用性的简单而强大的功能。负载平衡框架依赖于提供第4层负载平衡的著名且广泛使用的Linux虚拟服务器（IPVS）内核模块。Keepalived实现了一组VIP功能，以根据其运行状况动态，自适应地维护和管理负载平衡的服务器池。**另一方面，VRRP实现了高可用性 协议。VRRP是路由器故障转移的基础。**

**VRRP （Virtual Router Redundancy Protocol，虚拟路由器冗余协议）：** 在现实的网络环境中，主机之间的通信都是通过配置静态路由（默认网关）完成的， 而主机之间的路由器一旦出现故障，通信就会失败，因此，在这种通信模式中，路由器就成了一个单点瓶颈，为了解决这个问题，就引入了 VRRP 协议。

VRRP 可以将两台或多台物理路由器设备虚拟成一个虚拟路由器，每个虚拟路由器都有一个唯一标识，称为 VRID，一个 VRID 与一组 IP 地址构成了一个虚拟路由器。 这个虚拟路由器通过虚拟IP（一个或多个）对外提供服务。而在虚拟路由器内部，同一时间只有一台物理路由器对外提供服务，这台物理路由器被称为主路由器（处于 MASTER 角色）。 而其他物理路由器不拥有对外的虚拟 IP，也不提供对外网络功能，仅仅接收 MASTER 的 VRRP 状态通告信息，这些路由器被统称为备份路由器（处于 BACKUP 角色）。 当主路由器失效时，处于 BACKUP 角色的备份路由器将重新进行选举，产生一个新的主路由器进入 MASTER 角色继续提供对外服务，整个切换过程对用户来说完全透明。

- Nginx+Keepalived

  > Nginx 可以用来作为反向代理服务器，来提供负载均衡的能力，使我们的 Web 服务器，能够水平扩容，从而处理更多的用户请求，但是反向代理服务器又变成了一个单点，当反向代理服务器挂了，整合 Web 服务器就不能被外界访问到，所以我们必须要保证反向代理服务器的高可用。
  >
  > 而 Keepalived 是一种高性能的服务器高可用或热备解决方案，Keepalived 可以用来防止服务器单点故障的发生，通过配合 Nginx 可以实现 Web 前端服务的高可用。

- LVS+Keepalived

  > ![LVS集群的体系结构](images/lvs-architecture.jpg)

- 脑裂问题

  > 在高可用系统中，作为主备节点的两台服务器，可能因为一些比如说网络断开，两台机器的心跳检测会认为主挂了，但是主其实是正常的，只是网络断开了，心跳检测没法检查到主还活着，**由于主从之间失去了联系，都以为是对方发生了故障，所以两个节点都会主动的抢占资源，**争抢应用服务，争抢VIP，这样就发发生一些严重的后果，或者资源被瓜分了、或者是两边的节点都启动不起来了、或者是都起来了，但是同时读写共享存储，导致数据损坏。

#### LVS负载均衡及几种工作模式

LVS 是一个工作在四层的负载均衡器，它的实现和 iptables/netfilter 类似，工作在内核空间的 TCP/IP 协议栈上，LVS 工作在 INPUT Hook Funtion 上，并在 INPUT 设置附加规则，一旦客户端请求的是集群服务，LVS 会强行修改请求报文，将报文发往 POSTROUTING，转发至后端的主机。

- 相关术语

  > - LB (Load Balancer 负载均衡)
  > - HA (High Available 高可用)
  > - Failover (失败切换)
  > - Cluster (集群)
  > - LVS (Linux Virtual Server Linux 虚拟服务器)
  > - DS (Director Server)，指的是前端负载均衡器节点
  > - RS (Real Server)，后端真实的工作服务器
  > - VIP (Virtual IP)，虚拟的 IP 地址，向外部直接面向用户请求，作为用户请求的目标的 IP 地址
  > - DIP (Director IP)，主要用于和内部主机通讯的 IP 地址
  > - RIP (Real Server IP)，后端服务器的 IP 地址
  > - CIP (Client IP)，访问客户端的 IP 地址

- LVS-NAT

  > ![img](images/lvs-nat.jpg)
  >
  > LVS-NAT 模型类似于 DNAT，工作机制与 DNAT 一样，当客户端请求的是集群服务时，LVS 修改请求报文的目标地址为 RIP，转发至后端的 RealServer，并修改后端响应报文的源地址为 VIP，响应至客户端。
  >
  > 在 LVS-NAT 模型下，Director 进出请求报文都经过 Director，因此 Director 的压力是比较大的。
  >
  > LVS-NAT 的特性：
  >
  > - 集群节点跟 Director 必须在同一个 IP 网络中
  > - RIP 通常是私有地址，仅用于各集群节点间的通信
  > - Director 位于 client 和 Realserver 之间，负责处理进出的所有报文
  > - Realserver 必须将网关指向 DIP
  > - 支持端口映射
  > - 较大规模应用场景中，Director 易成为系统瓶颈（bottleneck）

- LVS-DR

  > ![img](images/lvs-dr.jpg)
  >
  > DR 值 Direct Routing，直接路由，DR 模型中，Director 和 Realserver 处在同一网络中，对于 Director，VIP 用于接受客户端请求，DIP 用于和 Realserver 通信。对于 Realserver，每个 Realserver 都配有和 Director 相同的 VIP（此 VIP 隐藏，关闭对 ARP 请求的响应），仅用户响应客户端的请求，RIP 用于和 Director 通信。
  >
  > 当客户端请求集群服务时，请求报文发送至 Director 的 VIP（Realserver的 VIP 不会响应 ARP 请求），Director 将客户端报文的源和目标 MAC 地址进行重新封装，将报文转发至 Realserver，Realserver 接收转发的报文。此时报文的源 IP 和目标 IP 都没有被修改，因此 Realserver 接受到的请求报文的目标 IP 地址为本机配置的 VIP，它将使用自己的 VIP 直接响应客户端。
  >
  > LVS-DR 模型中，客户端的响应报文不会经过 Director，因此 Director 的并发能力有很大提升。
  >
  > LVS-DR 模型的特性：
  >
  > - 保证前端路由器将目标地址为 VIP 的报文通过 ARP 解析后送往 Director。
  >   - 静态绑定：在前端路由将 VIP 对应的目标 MAC 地址静态配置为Director VIP 接口的 MAC 地址。
  >   - arptables：在各 Realserver 上，通过 arptables 规则拒绝其响应对 VIP 的 ARP 广播请求
  >   - 修改内核参数：在 Realserver 上修改内核参数，并结合地址的配置方式实现拒绝响应对 VIP 的 ARP 广播请求
  > - 各RIP 必须与 DIP 在同一个物理网络中
  > - RS 的 RIP 可以使用私有地址，也可以使用公网地址，以方便配置
  > - Director 仅负责处理入站请求，响应报文由 Realserver 直接发往客户端
  > - Realserver 不能将网关指向 DIP，而直接使用前端网关
  > - 不支持端口映射

- LVS-TUN

  > ![img](images/lvs-tun.jpg)
  >
  > 和 DR 模型类似，Realserver 都配有不可见的 VIP，Realserver 的 RIP 是公网地址，且可能和 DIP 不再同一网络中。当请求到达 Director 后，Director 不修改请求报文的源 IP 和目标 IP 地址，而是使用 IP 隧道技术，使用 DIP 作为源 IP，RIP 作为目标 IP 再次封装此请求报文，转发至 RIP 的 Realserver 上，Realserver 解析报文后仍然使用 VIP 作为源地址响应客户端。
  >
  > LVS-TUN 的特性：
  >
  > - 集群节点和可以跨越 Internet
  > - RIP，DIP，VIP 都是公网地址
  > - Director 仅负责处理入站请求，响应报文由 Realserver 直接发往客户端
  > - Realserver 使用自己的网关而不是 Director
  > - Realserver 只能使用支持隧道功能的操作系统
  > - 不支持端口映射

#### LVS和HAProxy相比，它的缺点是什么?

The most important thing that differentiates the two solutions (LVS, HAproxy) is that one is working at layer 4 (LVS) and the other at layer 7 (HAproxy). Note that the layers references are from OSI networking model.

If you understand this, you'll be able to use one in the right place. For example : if you need to balance based solely on number of connections (let's say), the layer 4 load balancer should suffice; on the other hand, if you want to load-balancer based on HTTP response time, you'll need a higher layer kind of LB.

The drawbacks of using a higher level LB is the resource needed (for the same amount of let's say, traffic). The plusses are obvious - think "packet level inspection", "protocol routing", etc - things far more complicated than simple "packet routing".

The last point I want to make is that HAproxy is userspace (think "far more easy to customize/tweak", but slower (performance)), while LVS is in kernel space (think "fast as hell", but rigid as the kernel). Also, don't forget about "upgrading LVS might mean kernel change - ergo, reboot"...

### 网络优化

#### CDN内容分发网络

#### TCP链接状态

在 TCP 的三次握手、数据传输以及四次挥手的过程中，我们给 Client 和 Server 定义了很多状态用于描述整个流程，结合上面的状态转换图来理解这些状态定义：

- LISTEN（Server）: 正在侦听来自远方的 TCP 端口的连接请求，服务端启动后处于 LISTEN 状态用于监听不同客户端的 TCP 请求并建立连接
- SYN-SENT（Client）: 三次握手时，Client 在发送 SYN 以请求后处于等待建立连接的状态
- SYN_RCVD（Server）：三次握手时，当 Server 收到 Client 的 SYN 信号时，将标志位 ACK 和 SYN 发送给 Client 后到建立连接之间，Server 处于 SYN_RCVD 状态
- ESTABLISHED（Server And Client）：三次握手成功以后，Client 和 Server 处于数据传输的状态
- FIN-WAIT-1（Client）：四次挥手时，Client 端发送中断请求 FIN 到收到 Server 端的中断确认的过程
- CLOSE_WAIT（Server）：四次挥手时，Client 接收到 Client 的 FIN 请求响应后回复 ACK 确认到发送 FIN 包的状态
- FIN-WAIT-2（Client）：四次挥手时，当 Client 接收到 Server 对于 FIN 的响应 ACK 后到收到 Server 端的 FIN 包的状态
- LAST_ACK（Server）：四次挥手时，Server 发送 FIN 请求关闭连接到关闭连接前的状态
- TIME_WAIT（Client）：四次挥手时 Client 对于 Server 的 FIN 回复 ACK 到连接关闭前的状态，又称 2MSL 状态
- CLOSE（Server And Client）：Server 和 CLient 关闭连接后的状态

正常情况下，客户端的状态转换流程如下：

```text
CLOSED -> SYN_SENT -> ESTABLISHED -> FIN_WAIT_1 -> FIN_WAIT_2 -> TIME_WAIT -> CLOSED
```

正常情况下，服务端的状态转换流程如下：

```text
CLOSED -> LISTEN -> SYN_RCVD -> ESTABLISHED -> CLOSE_WAIT -> LAST_ACK -> CLOSED
```

#### TCP/IP四层协议模型

![计算机网络模型](images/1739d1d409e3174b~tplv-t2oaga2asx-watermark.awebp)

- 消息发送流程

  > 第一层：应用层，主要有负责web浏览器的HTTP协议， 文件传输的FTP协议，负责电子邮件的SMTP协议，负责域名系统的DNS等。
  >
  > 第二层：传输层，主要是有**可靠传输**的TCP协议，特别**高效**的UDP协议。主要负责传输应用层的数据包。
  >
  > 第三层：网络层，主要是IP协议。主要负责寻址（找到目标设备的位置）
  >
  > 第四层：数据链路层，主要是负责转换数字信号和物理二进制信号。
  >
  > ![数据在网络中传输](images/1739d1d409d2edf0~tplv-t2oaga2asx-watermark.awebp)

### Web安全

#### 分布式架构下，Session共享有什么方案

#### 为什么Cookie无法防止CSRF，而Token可以？

#### Cookie和Session有什么区别？如何使用Session进行身份认证？

#### 认证和授权的区别是什么？

#### SSO的基本原理和认证流程？

#### 什么是CSRF？

### OSI模型

#### TCP的3次握手4次挥手

#### 四次挥手中TIME_WAIT的目的是什么

#### TCP和UDP有什么区别，各适合什么场景？

#### 如何查看TCP状态

#### HTTP和HTTPS的区别

#### TCP的拥塞控制

#### DNS解析过程

## Linux内核

### 文件系统与IO

#### epoll和poll之间有什么区别

#### DirtyPage脏页

脏页是Linux内核中的概念，因为硬盘的读写速度远赶不上内存的速度，系统就把读写比较频繁的数据事先放到内存中，以提高读写速度，这就叫高速缓存，linux是以页作为高速缓存的单位，当进程修改了高速缓存里的数据时，该页就被内核标记为脏页，内核将会在合适的时间把脏页的数据写到磁盘中去，以保持高速缓存中的数据和磁盘中的数据是一致的。

#### PageCache原理

因为硬盘和内存的读写性能差距巨大，Linux默认情况是以异步方式读写文件的。比如调用系统函数open()打开或者创建文件时缺省情况下是带有O_ASYNC flag的。Linux借助于内核的page cache来实现这种异步操作。

也就是说，我们平常向硬盘写文件时，默认异步情况下，并不是直接把文件内容写入到硬盘中才返回的，而是成功拷贝到内核的page cache后就直接返回，所以大多数情况下，硬盘写操作不会是性能瓶颈。写入到内核page cache的pages成为dirty pages，稍后会由内核线程pdflush真正写入到硬盘上。

从硬盘读取文件时，同样不是直接把硬盘上文件内容读取到用户态内存，而是先拷贝到内核的page cache，然后再“拷贝”到用户态内存，这样用户就可以访问该文件。因为涉及到硬盘操作，所以第一次读取一个文件时，不会有性能提升；不过，如果一个文件已经存在page cache中，再次读取该文件时就可以直接从page cache中命中读取不涉及硬盘操作，这时性能就会有很大提高。

下面用`dd`比较下异步（缺省模式）和同步写硬盘的速度差别：

```
$ dd if=/dev/urandom of=async.txt bs=64M count=16 iflag=fullblock
16+0 records in
16+0 records out
1073741824 bytes (1.1 GB, 1.0 GiB) copied, 7.618 s, 141 MB/s
$ dd if=/dev/urandom of=sync.txt bs=64M count=16 iflag=fullblock oflag=sync
16+0 records in
16+0 records out
1073741824 bytes (1.1 GB, 1.0 GiB) copied, 13.2175 s, 81.2 MB/s
```

page cache除了可以提升和硬盘交互性能外，下面继续讨论page cache功能。

- 如果程序crash，异步模式会丢失数据吗？

  > 比如存在这样的场景：一批数据已经成功写入到page cache，这时程序突然crash，但是在page cache里的数据还没来得及被pdflush写回到硬盘，这批数据会丢失吗？答案"是"，要看具体情况：
  >
  > 1. 如果OS没有crash或者重启的话，仅仅是写数据的程序crash，那么已经成功写入到page cache中的dirty pages是会被pdflush在合适的时机被写回到硬盘，不会丢失数据；
  > 2. 如果OS也crash或者重启的话，因为page cache存放在内存中，一旦断电就丢失了，那么就会丢失数据。
  >    至于这种情况下，会丢失多少数据，主要看系统重启前有多少dirty pages被写入到硬盘，已经成功写回硬盘的就不会丢失；没来得急写回硬盘的数据就彻底丢失了。这也是异步写硬盘的一个潜在风险。
  >    同步写硬盘时就不存在这种丢数据的风险。同步写操作返回成功时，能保证数据一定被保存在硬盘上了。
  >
  > 引用RocksDB wiki中关于“[Asynchronous Writes](https://github.com/facebook/rocksdb/wiki/Basic-Operations#asynchronous-writes)”描述：
  >
  > > Asynchronous writes are often more than a thousand times as fast as synchronous writes. The downside of asynchronous writes is that a crash of the machine may cause the last few updates to be lost. Note that a crash of just the writing process (i.e., not a reboot) will not cause any loss since even when sync is false, an update is pushed from the process memory into the operating system before it is considered done.
  >
  > 那么如何避免因为系统重启或者机器突然断电，导致数据丢失问题呢？
  > 可以借助于WAL（Write-Ahead Log）技术。
  >
  > WAL技术在数据库系统中比较常见，在数据库中一般又称之为redo log，Linux 文件系统ext3/ext4称之为journaling。WAL作用是：写数据库或者文件系统前，先把相关的metadata和文件内容写入到WAL日志中，然后才真正写数据库或者文件系统。WAL日志是append模式，所以，对WAL日志的操作要比对数据库或者文件系统的操作轻量级得多。如果对WAL日志采用同步写模式，那么WAL日志写成功，即使写数据库或者文件系统失败，可以用WAL日志来恢复数据库或者文件系统里的文件。

- 查看一个文件占用page cache情况

  > 可以借助于[vmtouch](https://hoytech.com/vmtouch/)工具（网上提到的linux-ftools中fincore已经停止维护，vmtouch功能类似）：
  >
  > > vmtouch is a tool for learning about and controlling the file system cache of unix and unix-like systems.
  >
  > 比如，有一个文件sample.txt:
  >
  > ```
  > $ ll sample.txt
  > -rw-r--r-- 1 root root 660000271 Mar 14 15:59 sample.txt
  > $ ll -h sample.txt
  > -rw-r--r-- 1 root root 630M Mar 14 15:59 sample.txt
  > ```
  >
  > 如果这个sample.txt文件从来没有被打开过，结果如下：
  >
  > ```
  > $ vmtouch sample.txt
  >            Files: 1
  >      Directories: 0
  >   Resident Pages: 0/161133  0/629M  0%
  >          Elapsed: 0.003136 seconds
  > ```
  >
  > 接着用vim打开这个sample.txt文件，因为这个文件比较大，所以vim会hang住一段时间。同时可以用`watch -n 1 vmtouch sample.txt`持续观察wmtouch输出，可以看到“Resident Pages”的值持续增长直到100%，这时vim也结束了hang的过程并接受用户操作。最终结果是：
  >
  > ```
  > $ vmtouch sample.txt
  >            Files: 1
  >      Directories: 0
  >   Resident Pages: 161133/161133  629M/629M  100%
  >          Elapsed: 0.022034 seconds
  > ```

#### BufferCache



## 云原生

