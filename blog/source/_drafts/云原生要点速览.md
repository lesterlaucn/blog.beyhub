云原生本身甚至不能称为是一种架构，它首先是一种基础设施，运行在其上的应用称作云原生应用，只有符合云原生设计哲学的应用架构才叫云原生应用架构。

## 设计模式及使用

### 资源对象

#### Pod

```shell
# 查看Pod运行状态
kubectl get pod task-pv-pod
# 打开一个shell，进入Pod
kubectl exec -it task-pv-pod -- /bin/bash
# 清理Pod
kubectl delete pod task-pv-pod
```

#### ReplicaSet

#### ReplicationController

#### Deployment

Deployment 为 Pod 和 Replica Set（下一代 Replication Controller）提供声明式更新。

您只需要在 Deployment 中描述您想要的目标状态是什么，Deployment controller 就会帮您将 Pod 和 ReplicaSet 的实际状态改变到您的目标状态。您可以定义一个全新的 Deployment 来创建 ReplicaSet 或者删除已有的 Deployment 并创建一个新的来替换。

**注意**：您不该手动管理由 Deployment 创建的 ReplicaSet，否则您就篡越了 Deployment controller 的职责！下文罗列了 Deployment 对象中已经覆盖了所有的用例。如果未有覆盖您所有需要的用例，请直接在 Kubernetes 的代码库中提 issue。

典型的用例如下：

- 使用 Deployment 来创建 ReplicaSet。ReplicaSet 在后台创建 pod。检查启动状态，看它是成功还是失败。
- 然后，通过更新 Deployment 的 PodTemplateSpec 字段来声明 Pod 的新状态。这会创建一个新的 ReplicaSet，Deployment 会按照控制的速率将 pod 从旧的 ReplicaSet 移动到新的 ReplicaSet 中。
- 如果当前状态不稳定，回滚到之前的 Deployment revision。每次回滚都会更新 Deployment 的 revision。
- 扩容 Deployment 以满足更高的负载。
- 暂停 Deployment 来应用 PodTemplateSpec 的多个修复，然后恢复上线。
- 根据 Deployment 的状态判断上线是否 hang 住了。
- 清除旧的不必要的 ReplicaSet。

#### StatefulSet

#### DaemonSet

#### Job

#### CronJob

#### HorizontalPodAutoscaler

### 配置对象

#### Node

#### Namespace

#### Service

#### Secret

#### ConfigMap

ConfigMap是用来存储配置文件的kubernetes资源对象，所有的配置内容都存储在etcd中。

更新 ConfigMap 后：

- 定义ConfigMap

  > ```yaml
  > kind: ConfigMap
  > apiVersion: v1
  > metadata:
  >   creationTimestamp: 2016-02-18T19:14:38Z
  >   name: example-config
  >   namespace: default
  > data:
  >     example.property.1: hello
  >     example.property.2: world
  >     flink-conf.yaml: |+
  >         jobmanager.rpc.address: flink-jobmanager-rpc
  >         taskmanager.numberOfTaskSlots: 4
  >         blob.server.port: 6124
  >         state.checkpoints.dir: /var/flink/checkpoints
  >         state.savepoints.dir: /var/flink/savepoints
  >         web.cancel.enable: true
  > ```

- 挂载ConfigMap

  > 方法1：在Deployment中挂载配置文件
  >
  > ```yaml
  > # deployment.yaml
  > .....
  > spec:
  >   containers:
  >   .....
  >     volumeMounts:
  >       - name: flink-config-volume
  >         mountPath: /opt/flink/conf/
  >   volumes:
  >     - name: flink-config-volume
  >       configMap:
  >         name: example-config # config-map名称
  >           items:
  >           - key: flink-conf.yaml
  >           path: flink-conf.yaml
  >           - key: log4j-console.properties
  >           path: log4j-console.properties
  > ```
  >
  > 方法2：在Pod中使用
  >
  > ```yaml
  > apiVersion: v1
  > kind: Pod
  > metadata:
  >   name: dapi-test-pod
  > spec:
  >   containers:
  >     - name: test-container
  >       image: gcr.io/google_containers/busybox
  >       command: [ "/bin/sh", "-c", "env" ]
  >       env:
  >         - name: SPECIAL_LEVEL_KEY
  >           valueFrom:
  >             configMapKeyRef:
  >               name: special-config
  >               key: special.how
  >         - name: SPECIAL_TYPE_KEY
  >           valueFrom:
  >             configMapKeyRef:
  >               name: special-config
  >               key: special.type
  >       envFrom:
  >         - configMapRef:
  >             name: env-config
  >   restartPolicy: Never
  > ```

- 使用该 ConfigMap 挂载的 Env **不会**同步更新

  > ENV 是在容器启动的时候注入的，启动之后 kubernetes 就不会再改变环境变量的值，且同一个 namespace 中的 pod 的环境变量是不断累加的

- 使用该 ConfigMap 挂载的 Volume 中的数据需要一段时间（实测大概10秒）才能同步更新

  > 更新 ConfigMap 目前并不会触发相关 Pod 的滚动更新，可以通过修改 pod annotations 的方式强制触发滚动更新。
  >
  > ```bash
  > $ kubectl patch deployment my-nginx --patch '{"spec": {"template": {"metadata": {"annotations": {"version/config": "20180411" }}}}}'
  > ```
  >
  > 这个例子里我们在 `.spec.template.metadata.annotations` 中添加 `version/config`，每次通过修改 `version/config` 来触发滚动更新。

#### Ingress

#### Label

#### CustomResourceDefinition

#### ServiceAccount

### 策略对象

#### SecurityContext

#### ResourceQuota

#### LimitRange

### 存储对象

#### Volume

- Kubernetes 支持以下类型的卷：

  > cephfs`/`csi/`downwardAPI`/`emptyDi/fc (fibre channel) / flocker / gcePersistentDisk/gitRepo/glusterfs`/`hostPath / iscsi / local / nfs / persistentVolumeClaim / projected / portworxVolume / quobyte / rbd / scaleIO / secret / storageos / vsphereVolume / ConfigMap

- emptyDir

  > 当 Pod 被分配给节点时，首先创建 `emptyDir` 卷，并且只要该 Pod 在该节点上运行，该卷就会存在。正如卷的名字所述，它最初是空的。Pod 中的容器可以读取和写入 `emptyDir` 卷中的相同文件，尽管该卷可以挂载到每个容器中的相同或不同路径上。当出于任何原因从节点中删除 Pod 时，`emptyDir` 中的数据将被永久删除。
  >
  > **注意**：容器崩溃不会从节点中移除 pod，因此 `emptyDir` 卷中的数据在容器崩溃时是安全的。
  >
  > `emptyDir` 的用法有：
  >
  > - 暂存空间，例如用于基于磁盘的合并排序
  > - 用作长时间计算崩溃恢复时的检查点
  > - Web服务器容器提供数据时，保存内容管理器容器提取的文件
  >
  > ```yaml
  > apiVersion: v1
  > kind: Pod
  > metadata:
  >   name: test-pd
  > spec:
  >   containers:
  >   - image: k8s.gcr.io/test-webserver
  >     name: test-container
  >     volumeMounts:
  >     - mountPath: /cache
  >       name: cache-volume
  >   volumes:
  >   - name: cache-volume
  >     emptyDir: {}
  > ```

- `persistentVolumeClaim` 

  > 卷用于将 PersistentVolume挂载到容器中。PersistentVolumes 是在用户不知道特定云环境的细节的情况下“声明”持久化存储（例如 GCE PersistentDisk 或 iSCSI 卷）的一种方式。

- hostPath卷：Pod直接挂载本地目录

  > `hostPath` 卷将主机节点的文件系统中的文件或目录挂载到集群中。该功能大多数 Pod 都用不到，但它为某些应用程序提供了一个强大的解决方法。
  >
  > 例如，`hostPath` 的用途如下：
  >
  > - 运行需要访问 Docker 内部的容器；使用 `/var/lib/docker` 的 `hostPath`
  > - 在容器中运行 cAdvisor；使用 `/dev/cgroups` 的 `hostPath`
  > - 允许 pod 指定给定的 hostPath 是否应该在 pod 运行之前存在，是否应该创建，以及它应该以什么形式存在
  >
  > 除了所需的 `path` 属性之外，用户还可以为 `hostPath` 卷指定 `type`。
  >
  > `type` 字段支持以下值：
  >
  > | 值                  | 行为                                                         |
  > | :------------------ | :----------------------------------------------------------- |
  > |                     | 空字符串（默认）用于向后兼容，这意味着在挂载 hostPath 卷之前不会执行任何检查。 |
  > | `DirectoryOrCreate` | 如果在给定的路径上没有任何东西存在，那么将根据需要在那里创建一个空目录，权限设置为 0755，与 Kubelet 具有相同的组和所有权。 |
  > | `Directory`         | 给定的路径下必须存在目录                                     |
  > | `FileOrCreate`      | 如果在给定的路径上没有任何东西存在，那么会根据需要创建一个空文件，权限设置为 0644，与 Kubelet 具有相同的组和所有权。 |
  > | `File`              | 给定的路径下必须存在文件                                     |
  > | `Socket`            | 给定的路径下必须存在 UNIX 套接字                             |
  > | `CharDevice`        | 给定的路径下必须存在字符设备                                 |
  > | `BlockDevice`       | 给定的路径下必须存在块设备                                   |
  >
  > 使用这种卷类型是请注意，因为：
  >
  > - 由于每个节点上的文件都不同，具有相同配置（例如从 podTemplate 创建的）的 pod 在不同节点上的行为可能会有所不同
  > - 当 Kubernetes 按照计划添加资源感知调度时，将无法考虑 `hostPath` 使用的资源
  > - 在底层主机上创建的文件或目录只能由 root 写入。您需要在特权容器中以 root 身份运行进程，或修改主机上的文件权限以便写入 `hostPath` 卷
  >
  > 示例：
  >
  > ```yaml
  > apiVersion: v1
  > kind: Pod
  > metadata:
  >   name: test-pd
  > spec:
  >   containers:
  >   - image: k8s.gcr.io/test-webserver
  >     name: test-container
  >     volumeMounts:
  >     - mountPath: /test-pd
  >       name: test-volume
  >   volumes:
  >   - name: test-volume
  >     hostPath: # 存储卷的类型
  >       # directory location on host
  >       path: /data
  >       # this field is optional
  >       type: Directory
  > ```

- projected

  > `projected` 卷将几个现有的卷源映射到同一个目录中。
  >
  > 目前，可以映射以下类型的卷来源：
  >
  > - [`secret`](https://jimmysong.io/kubernetes-handbook/concepts/volume.html#secret)
  > - [`downwardAPI`](https://jimmysong.io/kubernetes-handbook/concepts/volume.html#downwardapi)
  > - `configMap`
  >
  > 所有来源都必须在与 pod 相同的命名空间中。
  >
  > 带有 secret、downward API 和 configmap 的 pod
  >
  > ```yaml
  > apiVersion: v1
  > kind: Pod
  > metadata:
  >   name: volume-test
  > spec:
  >   containers:
  >   - name: container-test
  >     image: busybox
  >     volumeMounts:
  >     - name: all-in-one
  >       mountPath: "/projected-volume"
  >       readOnly: true
  >   volumes:
  >   - name: all-in-one
  >     projected:
  >       sources:
  >       - secret:
  >           name: mysecret
  >           items:
  >             - key: username
  >               path: my-group/my-username
  >       - downwardAPI:
  >           items:
  >             - path: "labels"
  >               fieldRef:
  >                 fieldPath: metadata.labels
  >             - path: "cpu_limit"
  >               resourceFieldRef:
  >                 containerName: container-test
  >                 resource: limits.cpu
  >       - configMap:
  >           name: myconfigmap
  >           items:
  >             - key: config
  >               path: my-group/my-config
  > ```
  >
  > #### 使用非默认权限模式设置多个 secret 的示例 pod
  >
  > ```yaml
  > apiVersion: v1
  > kind: Pod
  > metadata:
  >   name: volume-test
  > spec:
  >   containers:
  >   - name: container-test
  >     image: busybox
  >     volumeMounts:
  >     - name: all-in-one
  >       mountPath: "/projected-volume"
  >       readOnly: true
  >   volumes:
  >   - name: all-in-one
  >     projected:
  >       sources:
  >       - secret:
  >           name: mysecret
  >           items:
  >             - key: username
  >               path: my-group/my-username
  >       - secret:
  >           name: mysecret2
  >           items:
  >             - key: password
  >               path: my-group/my-password
  >               mode: 511
  > ```
  >
  > 每个映射的卷来源在 `sources` 下的规格中列出。除了以下两个例外，参数几乎相同：
  >
  > - 对于 secret，`secretName` 字段已经被更改为 `name` 以与 ConfigMap 命名一致。
  > - `defaultMode` 只能在映射级别指定，而不能针对每个卷源指定。但是，如上所述，您可以明确设置每个映射的 `mode`。

#### StorageClass

`StorageClass` 为管理员提供了描述存储 "class（类）" 的方法。 不同的 class 可能会映射到不同的服务质量等级或备份策略，或由群集管理员确定的任意策略。 Kubernetes 本身不清楚各种 class 代表的什么。这个概念在其他存储系统中有时被称为“配置文件”。

hostPath 类型的 PersistentVolume 使用节点上的文件或目录来模拟网络附加存储。已K3S为例，hostPath实际上为我们创建了一个本地目录用于存储文件：`/var/lib/rancher/k3s/storage/pvc-1b914241-aebf-416b-86e0-7371984775ad_devops_jenkins`。

- 存储分配器

  > Storage class 有一个分配器，用来决定使用哪个卷插件分配 PV。该字段必须指定。
  >
  > | Volume Plugin        | Internal Provisioner | Config Example                                               |
  > | -------------------- | -------------------- | ------------------------------------------------------------ |
  > | AWSElasticBlockStore | ✓                    | [AWS](https://kubernetes.io/docs/concepts/storage/storage-classes/#aws) |
  > | AzureFile            | ✓                    | [Azure File](https://kubernetes.io/docs/concepts/storage/storage-classes/#azure-file) |
  > | AzureDisk            | ✓                    | [Azure Disk](https://kubernetes.io/docs/concepts/storage/storage-classes/#azure-disk) |
  > | CephFS               | -                    | -                                                            |
  > | Cinder               | ✓                    | [OpenStack Cinder](https://kubernetes.io/docs/concepts/storage/storage-classes/#openstack-cinder) |
  > | FC                   | -                    | -                                                            |
  > | FlexVolume           | -                    | -                                                            |
  > | Flocker              | ✓                    | -                                                            |
  > | GCEPersistentDisk    | ✓                    | [GCE](https://kubernetes.io/docs/concepts/storage/storage-classes/#gce) |
  > | Glusterfs            | ✓                    | [Glusterfs](https://kubernetes.io/docs/concepts/storage/storage-classes/#glusterfs) |
  > | iSCSI                | -                    | -                                                            |
  > | PhotonPersistentDisk | ✓                    | -                                                            |
  > | Quobyte              | ✓                    | [Quobyte](https://kubernetes.io/docs/concepts/storage/storage-classes/#quobyte) |
  > | NFS                  | -                    | -                                                            |
  > | RBD                  | ✓                    | [Ceph RBD](https://kubernetes.io/docs/concepts/storage/storage-classes/#ceph-rbd) |
  > | VsphereVolume        | ✓                    | [vSphere](https://kubernetes.io/docs/concepts/storage/storage-classes/#vsphere) |
  > | PortworxVolume       | ✓                    | [Portworx Volume](https://kubernetes.io/docs/concepts/storage/storage-classes/#portworx-volume) |
  > | ScaleIO              | ✓                    | [ScaleIO](https://kubernetes.io/docs/concepts/storage/storage-classes/#scaleio) |
  > | StorageOS            | ✓                    | [StorageOS](https://kubernetes.io/docs/concepts/storage/storage-classes/#storageos) |

- 回收策略

  > Retain（保留）——手动回收
  >
  > Recycle（回收）——基本擦除（`rm -rf /thevolume/*`）
  >
  > Delete（删除）——关联的存储资产（例如 AWS EBS、GCE PD、Azure Disk 和 OpenStack Cinder 卷）将被删除

- StorageClass资源模板

```yaml
kind: StorageClass
apiVersion: storage.k8s.io/v1
metadata:
  name: standard
provisioner: kubernetes.io/aws-ebs
parameters:
  type: gp2
reclaimPolicy: Retain
mountOptions:
  - debug
```

#### PersistentVolume

`PersistentVolume`（PV）是由管理员设置的存储，它是**群集的一部分**。就像节点是集群中的资源一样，PV 也是集群中的资源。 PV 是 Volume 之类的卷插件，但具有独立于使用 PV 的 Pod 的生命周期。此 API 对象包含存储实现的细节，即 NFS、iSCSI 或特定于云供应商的存储系统。以下为PV资源模板：

```yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: task-pv-volume
  labels:
    type: local
spec:
  storageClassName: manual
  capacity:
    storage: 10Gi
  accessModes:
    - ReadWriteOnce
  hostPath:
    path: "/mnt/data"
```

#### PersistentVolumeClaim

`PersistentVolumeClaim`（PVC）是用户存储的请求。它与 Pod 相似。Pod 消耗节点资源，PVC 消耗 PV 资源。Pod 可以请求特定级别的资源（CPU 和内存）。声明可以请求特定的大小和访问模式（例如，可以以读/写一次或 只读多次模式挂载）。

1. 创建PersistentVolumeClaim

```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: task-pv-claim
spec:
  storageClassName: manual
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 3Gi
```

2. 在Pod中使用存储

注意 Pod 的配置文件指定了 PersistentVolumeClaim，但没有指定 PersistentVolume。 对 Pod 而言，PersistentVolumeClaim 就是一个存储卷。

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: task-pv-pod
spec:
  volumes:
    - name: task-pv-storage
      persistentVolumeClaim:
        claimName: task-pv-claim
  containers:
    - name: task-pv-container
      image: nginx
      ports:
        - containerPort: 80
          name: "http-server"
      volumeMounts:
        - mountPath: "/usr/share/nginx/html"
          name: task-pv-storage
```

4. 两个地方挂载相同的pv

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: test
spec:
  containers:
    - name: test
      image: nginx
      volumeMounts:
        # 网站数据挂载
        - name: config
          mountPath: /usr/share/nginx/html
          subPath: html
        # Nginx 配置挂载
        - name: config
          mountPath: /etc/nginx/nginx.conf
          subPath: nginx.conf # 注释使用subPath
  volumes:
    - name: config
      persistentVolumeClaim:
        claimName: test-nfs-claim
```

#### ConfigMap

## 参考资料

1. https://jimmysong.io/kubernetes-handbook/
2. https://kubernetes.io/docs/tasks/configure-pod-container/configure-persistent-volume-storage/